{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "fdc0a54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "from Levenshtein import distance\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "# connect to the SQLite database and read the data into a pandas dataframe\n",
    "conn = sqlite3.connect('data_files/spanish/words.db')\n",
    "df = pd.read_sql('SELECT * FROM words', conn)\n",
    "\n",
    "# close the database connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "c4d5573e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['word', 'type', 'translation', 'example', 'example_translation',\n",
       "       'russian', 'appear', 'trial_d', 'trial_r', 'success', 'weight',\n",
       "       'word_index'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e9848f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['difficulty', 'wd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "95b47547",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = list(df.columns)\n",
    "\n",
    "df['Length_word'] = df['word'].str.len()\n",
    "df['translation'] = df['translation'].str.split(',').str[0]\n",
    "df['Length_translation'] = df['translation'].str.len()\n",
    "# Calculate Levenshtein Distance between word and translation\n",
    "df['Similarity'] = df.apply(lambda row: fuzz.ratio(row['word'], row['translation']), axis=1)\n",
    "    \n",
    "# dividing into quantiles\n",
    "df['d1'] = pd.qcut(df['Length_word'], q=4, labels=[0, 1, 2, 3])\n",
    "df['d1'] = df['d1'].astype(int)\n",
    "df['d2'] = pd.qcut(df['Length_translation'], q=3, labels=[0, 1, 2])\n",
    "df['d2'] = df['d2'].astype(int)\n",
    "df['d3'] = pd.qcut(df['Similarity'], q=5, labels=[4, 3, 2, 1, 0])\n",
    "df['d3'] = df['d3'].astype(int)\n",
    "df['d4'] = pd.cut(df['weight'], bins=3, labels=[1, 2, 3])\n",
    "df['d4'] = df['d4'].astype(int)\n",
    "\n",
    "df['difficulty'] = df['d1'] + df['d2'] + df['d3']\n",
    "df['wd'] = df['d1'] + df['d2'] + df['d3'] + df['d4']\n",
    "\n",
    "columns = columns + ['difficulty', 'wd']\n",
    "\n",
    "df = df.loc[:, columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "ee202aea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5,  6,  4,  2,  7,  8,  3,  9, 10, 11])"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['wd'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "4ff6136c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xlstosql(df):\n",
    "    df_name = df.name\n",
    "    # connect to the SQLite database\n",
    "    conn = sqlite3.connect(f'data_files/spanish/{df_name}.db')\n",
    "    # insert the data from the dataframe into the database table\n",
    "    df.to_sql(f'{df_name}', conn, if_exists='replace', index=False)\n",
    "    # close the database connection\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "98a28898",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.name = 'words'\n",
    "xlstosql(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "811f7da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dif_df = df.loc[:, ['word_index', 'difficulty']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "562741a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('data_files/spanish/words.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(\"ALTER TABLE words ADD COLUMN word_index INTEGER\")\n",
    "\n",
    "cursor.execute(\"SELECT rowid FROM words\")\n",
    "rows = cursor.fetchall()\n",
    "\n",
    "for i, row in enumerate(rows, start=1):\n",
    "    cursor.execute(\"UPDATE words SET word_index = ? WHERE rowid = ?\", (i, row[0]))\n",
    "conn.commit()\n",
    "\n",
    "# Сохранение изменений и закрытие соединения\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "b51032d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def difficulty(df, level='standard'):\n",
    "    \n",
    "    columns = list(df.columns)\n",
    "    \n",
    "    df['Length_word'] = df['word'].str.len()\n",
    "    df['translation'] = df['translation'].str.split(',').str[0]\n",
    "    df['Length_translation'] = df['translation'].str.len()\n",
    "    # Calculate Levenshtein Distance between word and translation\n",
    "    df['Similarity'] = df.apply(lambda row: fuzz.ratio(row['word'], row['translation']), axis=1)\n",
    "    \n",
    "    # dividing into quantiles\n",
    "    df['d1'] = pd.qcut(df['Length_word'], q=4, labels=[0, 1, 2, 3])\n",
    "    df['d1'] = df['d1'].astype(int)\n",
    "    df['d2'] = pd.qcut(df['Length_translation'], q=3, labels=[0, 1, 2])\n",
    "    df['d2'] = df['d2'].astype(int)\n",
    "    df['d3'] = pd.qcut(df['Similarity'], q=5, labels=[4, 3, 2, 1, 0])\n",
    "    df['d3'] = df['d3'].astype(int)\n",
    "    df['d4'] = pd.qcut(df['weight'], bins=3, labels=[1, 2, 3], duplicates='drop')\n",
    "    df['d4'] = df['d4'].astype(int)\n",
    "    \n",
    "    df['difficulty'] = df['d1'] + df['d2'] + df['d3'] + df['d4']\n",
    "    \n",
    "    \n",
    "    \n",
    "    df = df.loc[:, columns]\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "20fa45a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate word lengths and divide into three bins\n",
    "#df['Difficulty'] = pd.cut(df['Length'], bins=3, labels=['Easy', 'Medium', 'Hard'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "e23f27c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = []\n",
    "\n",
    "for i in range(0,101):\n",
    "    test_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "99c3d149",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt=pd.DataFrame()\n",
    "tt['count'] = test_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "b33566f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt['dif'] = pd.cut(test_list, bins=3, labels=['Easy', 'Medium', 'Hard'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "b14d4806",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('data_files/tdddt.xlsx')\n",
    "df.to_excel(writer, sheet_name='update')\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "83fddef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn2 = sqlite3.connect('data_files/lessons.db')\n",
    "lesson = pd.read_sql('SELECT * FROM lessons', conn2)\n",
    "conn2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "25c04e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lesson_df = lesson[lesson['known'] != 25]\n",
    "lesson_df = lesson_df.loc[:, ['r', 'list_of_words', 'points']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "5d0dae21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a sample difficulty DataFrame\n",
    "difficulty_df = df.loc[:,['word', 'difficulty']]\n",
    "\n",
    "# Split 'list of words' column and retrieve difficulties\n",
    "lesson_df['words'] = lesson_df['list_of_words'].str.split(';')\n",
    "lesson_df['words'] = lesson_df['words'].apply(lambda x: [word.strip() for word in x])\n",
    "lesson_df['dif'] = lesson_df['words'].apply(lambda x: sum(difficulty_df[difficulty_df['word'].isin(x)]['difficulty']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "59af379e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the intermediate 'words' column\n",
    "lesson_df.drop('words', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "12d7c04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('data_files/test_check.xlsx')\n",
    "lesson_df.to_excel(writer, sheet_name='update')\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "f8abecbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a unique key column based on index\n",
    "df['key'] = df.index\n",
    "\n",
    "# Define the desired distribution of words by difficulty\n",
    "difficulty_distribution_easy = {1: 4, 2: 4, 3: 4, 4: 4, 5: 4, 6:2, 7:1, 8:1 , 9:1, 10:0}\n",
    "difficulty_distribution = {1: 2, 2: 2, 3: 3, 4: 3, 5: 3, 6: 3, 7:3, 8:2 ,9:2, 10:2 }\n",
    "difficulty_distribution_hard = {1: 0, 2: 1, 3: 1, 4: 1, 5: 2, 6: 4, 7:4, 8:4 ,9:4, 10:4 }\n",
    "difficulty_distribution_hardest = {1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 5, 7:5, 8:5 ,9:5, 10:5 }\n",
    "\n",
    "# Sample words from each difficulty level based on difficulty and weight\n",
    "selected_words = []\n",
    "for difficulty, count in difficulty_distribution.items():\n",
    "    words_subset = df[(df['wb'] == difficulty)]\n",
    "    words_subset = words_subset.sample(n=count, weights=words_subset['weight'])\n",
    "    selected_words.append(words_subset)\n",
    "    \n",
    "# Concatenate the selected words into a new DataFrame\n",
    "new_words_df = pd.concat(selected_words)\n",
    "\n",
    "writer = pd.ExcelWriter('data_files/new.xlsx')\n",
    "new_words_df.to_excel(writer, sheet_name='update')\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "008951e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index of the new DataFrame\n",
    "new_words_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Update the parameters of the selected words\n",
    "new_words_df['weight'] = new_words_df['weight'] * 2  # Update the weight parameter as an example\n",
    "\n",
    "# Merge the updated words with the original DataFrame based on the key column\n",
    "df = pd.merge(df, new_words_df, on='key', how='left')\n",
    "\n",
    "# Fill missing values in the original DataFrame with the updated values\n",
    "df['difficulty_y'].fillna(df['difficulty_x'], inplace=True)\n",
    "df['weight_y'].fillna(df['weight_x'], inplace=True)\n",
    "\n",
    "# Drop redundant columns from the merged DataFrame\n",
    "df.drop(['difficulty_x', 'weight_x', 'key'], axis=1, inplace=True)\n",
    "df.rename(columns={'difficulty_y': 'difficulty', 'weight_y': 'weight'}, inplace=True)\n",
    "\n",
    "writer = pd.ExcelWriter('data_files/final.xlsx')\n",
    "df.to_excel(writer, sheet_name='update')\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b76dd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "', '.join(list(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ddfa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import random\n",
    "\n",
    "difficulty_distribution = {1: 1, 2: 1, 3: 2, 4: 2, 5: 3, 6: 3, 7: 3, 8: 3, 9: 3, 10: 2, 11: 1, 12: 1}\n",
    "\n",
    "def sql_text(dffty, limit):\n",
    "    text = f\"\"\"\n",
    "    SELECT word, type, translation, russian, example, example_translation, appear, trial_d, trial_r, success, weight, word_index, difficulty, wd\n",
    "    FROM words\n",
    "    WHERE wd = {dffty}\n",
    "    ORDER BY weight DESC, RANDOM()\n",
    "    LIMIT {limit};\n",
    "    \"\"\"\n",
    "    return text\n",
    "\n",
    "def loadData(source, final='no'):\n",
    "    # connect to the SQLite database and read the data into a pandas dataframe\n",
    "    conn = sqlite3.connect('data_files/words.db')\n",
    "    \n",
    "    \n",
    "    if source == 'word' and final == 'no':\n",
    "        cursor = conn.cursor()\n",
    "        # Sample words from each difficulty level based on difficulty and weight\n",
    "        selected_words = []\n",
    "        for difficulty, count in difficulty_distribution.items():\n",
    "            # Retrieve 5 easy words\n",
    "            words_query = sql_text(difficulty, count)\n",
    "            cursor.execute(words_query)\n",
    "            selected_words = selected_words + cursor.fetchall()\n",
    "        return selected_words\n",
    "    else:\n",
    "        df = pd.read_sql(f'SELECT * FROM {source}s', conn)\n",
    "        df = df.loc[:, f'{source}':]\n",
    "        \n",
    "    # close the database connection\n",
    "    conn.close()\n",
    "    \n",
    "\n",
    "combined_data = loadData('word')\n",
    "\n",
    "    \n",
    "class Words(object):\n",
    "\n",
    "    \"\"\"The class for all words from dictionary. Each word a type, a translation, an example,\n",
    "    a translation of an example, a translation to Russian, also additional parameters which would be created after\n",
    "    the first run (quantity of appearances in lessons, trials of direct and indirect translation,\n",
    "    success attempts, also weight, more weight - more often words appear\"\"\"\n",
    "\n",
    "    def __init__(self, word, typ, translation, russian, example, example_translation, appear, trial_d, trial_r, success,\n",
    "                 weight, word_index, difficulty, wd):\n",
    "        self.word = word\n",
    "        self.typ = typ\n",
    "        self.translation = translation\n",
    "        self.example = example\n",
    "        self.example_translation = example_translation\n",
    "        self.russian = russian\n",
    "        self.appear = appear\n",
    "        self.trial_d = trial_d\n",
    "        self.trial_r = trial_r\n",
    "        self.success = success\n",
    "        self.weight = weight\n",
    "        self.word_index = word_index\n",
    "        self.difficulty = difficulty\n",
    "        self.wd = wd\n",
    "\n",
    "\n",
    "# Create Word objects from the combined data\n",
    "word_objects = []\n",
    "for row in combined_data:\n",
    "    word = Words(*row)\n",
    "    word_objects.append(word)\n",
    "\n",
    "# Print the created Word objects\n",
    "for word in word_objects:\n",
    "    print(f\"Word: {word.word}, Translation: {word.translation}, Weight: {word.weight}, Difficulty: {word.wd}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a77cee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sql_text(dffty, limit):\n",
    "    text = f\"\"\"\n",
    "    SELECT word, type, translation, russian, example, example_translation, appear, trial_d, trial_r, success, weight, word_index, difficulty, wd\n",
    "    FROM words\n",
    "    WHERE wd = {dffty}\n",
    "    ORDER BY weight DESC, RANDOM()\n",
    "    LIMIT {limit};\n",
    "    \"\"\"\n",
    "    return text\n",
    "\n",
    "\n",
    "# connect to the SQLite database and read the data into a pandas dataframe\n",
    "conn = sqlite3.connect('data_files/words.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Retrieve 5 easy words\n",
    "easy_words_query = sql_text(2, 15)\n",
    "cursor.execute(easy_words_query)\n",
    "easy_words = cursor.fetchall()\n",
    "\n",
    "# Retrieve 5 standard words\n",
    "standard_words_query = sql_text(6, 20)\n",
    "cursor.execute(standard_words_query)\n",
    "standard_words = cursor.fetchall()\n",
    "\n",
    "# Retrieve 5 hard words\n",
    "hard_words_query = sql_text(10, 5)\n",
    "cursor.execute(hard_words_query)\n",
    "hard_words = cursor.fetchall()\n",
    "\n",
    "# Close the database connection\n",
    "conn.close()\n",
    "\n",
    "# Print the retrieved words\n",
    "\n",
    "print(\"\\nEasy Words:\")\n",
    "for row in easy_words:\n",
    "    print(row)\n",
    "\n",
    "print(\"\\nStandard Words:\")\n",
    "for row in standard_words:\n",
    "    print(row)\n",
    "\n",
    "print(\"\\nHard Words:\")\n",
    "for row in hard_words:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "8c96ce5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text = \"\"\"\n",
    "    SELECT weight, word_index, wd\n",
    "    FROM words\n",
    "    \"\"\"\n",
    "\n",
    "# connect to the SQLite database and read the data into a pandas dataframe\n",
    "conn = sqlite3.connect('data_files/words.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Retrieve 5 easy words\n",
    "easy_words_query = text\n",
    "cursor.execute(easy_words_query)\n",
    "easy_words = cursor.fetchall()\n",
    "\n",
    "# Close the database connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "6657e68f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 2, 3)"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "easy_words[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "9131dbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('data_files/words.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "v1 = 100\n",
    "v2 = 100\n",
    "v3 = 100\n",
    "v4 = 100\n",
    "v5 = 100\n",
    "\n",
    "cursor.execute(\"UPDATE words SET appear = ?, trial_d = ?, trial_r = ?, success = ?, wd = ?  WHERE word_index = ?\",\n",
    "            (v1, v2, v3, v4, v5, 1))\n",
    "\n",
    "    # Commit the changes and close the connection\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "fccee63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "\n",
    "UPDATE words\n",
    "SET weight = \n",
    "             CASE\n",
    "                WHEN trial_d = 0 AND trial_r = 0 THEN ROUND(100, 2)\n",
    "                ELSE ROUND((100 - (success / (trial_d + trial_r)) * 100), 2)\n",
    "             END;\n",
    "\"\"\"\n",
    "\n",
    "conn = sqlite3.connect('data_files/words.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(text)\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "7edf7182",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "\n",
    "UPDATE words\n",
    "SET weight = \n",
    "    CASE\n",
    "        WHEN trial_d = 0 AND trial_r = 0 THEN ROUND(100, 2)\n",
    "        ELSE ROUND((100 - success * 100 /(trial_d + trial_r)), 2)\n",
    "    END;\n",
    "\"\"\"\n",
    "\n",
    "conn = sqlite3.connect('data_files/words.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(text)\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "f4570fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('data_files/lessons.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(\"SELECT lesson FROM lessons WHERE lesson IS NOT NULL ORDER BY lesson DESC LIMIT 1\")\n",
    "last_lesson = cursor.fetchone()[0]\n",
    "l1 = last_lesson + 1\n",
    "l2 = 0\n",
    "l3 = 0\n",
    "l4 = 0\n",
    "l5 = 0\n",
    "l6 = 0\n",
    "l7 = 0\n",
    "l8 = 0\n",
    "l9 = 0\n",
    "l10 = 0\n",
    "    \n",
    "cols = 'lesson, start, inter, finish, known, points, length, time, list_of_words, r'\n",
    "\n",
    "cursor.execute(f\"INSERT INTO lessons ({cols}) VALUES (?,?,?,?,?,?,?,?,?,?)\", (l1,l2,l3,l4,l5,l6,l7,l8,l9,l10))\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673bee7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Соединение с базой данных SQLite3\n",
    "conn = sqlite3.connect('data_files/lessons.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Выполнение запроса SELECT для получения уникальных значений из столбца\n",
    "cursor.execute(\"SELECT DISTINCT r FROM lessons\")\n",
    "results = cursor.fetchall()\n",
    "\n",
    "# Вывод уникальных значений в консоль\n",
    "for row in results:\n",
    "    print(row[0])\n",
    "\n",
    "# Закрытие соединения с базой данных\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "64e01d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn1 = sqlite3.connect('data_files/words.db')\n",
    "cursor1 = conn1.cursor()\n",
    "\n",
    "cursor1.execute('SELECT word_index, word FROM words')\n",
    "results = cursor1.fetchall()\n",
    "\n",
    "conn1.close()\n",
    "\n",
    "\n",
    "# Соединение с базой данных SQLite3\n",
    "conn = sqlite3.connect('data_files/lessons.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Выполнение запроса SELECT для получения уникальных значений из столбца\n",
    "cursor.execute(\"SELECT list_of_words FROM lessons\")\n",
    "lessons_x = cursor.fetchall()\n",
    "\n",
    "\n",
    "conn.close()\n",
    "\n",
    "\n",
    "for k, les in enumerate(lessons_x):\n",
    "    for row in les:\n",
    "        lesson_words = row.split(\";\")\n",
    "        for i, cw in enumerate(lesson_words):\n",
    "            lesson_words[i] = cw.strip()\n",
    "\n",
    "            for res in results:\n",
    "                if res[1] == lesson_words[i]:\n",
    "                    lesson_words[i] = res[0]\n",
    "    lessons_x[k] = lesson_words\n",
    "\n",
    "clmn = list(zip(*lessons_x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece33762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Соединение с базой данных SQLite3\n",
    "conn = sqlite3.connect('data_files/lessons.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "#cursor.execute(\"ALTER TABLE lessons ADD COLUMN new_col TEXT;\")\n",
    "\n",
    "# Выполнение запроса SELECT для получения уникальных значений из столбца\n",
    "cursor.execute(\"UPDATE lessons SET ind = clmn;\")\n",
    "\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc05220c",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn1 = sqlite3.connect('data_files/words.db')\n",
    "cursor1 = conn1.cursor()\n",
    "\n",
    "cursor1.execute('SELECT word_index, word FROM words')\n",
    "results = cursor1.fetchall()\n",
    "\n",
    "conn1.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
